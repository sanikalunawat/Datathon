# -*- coding: utf-8 -*-
"""Copy of location.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QGppLzSXduwEFn6oIj8ORwWyvPun5n46
"""

import pandas as pd
import random

city_streets = {
	"Los Angeles": [
    	"Sunset Boulevard", "Hollywood Boulevard", "Wilshire Boulevard", "Santa Monica Boulevard",
    	"Melrose Avenue", "Venice Boulevard", "Beverly Boulevard", "Rodeo Drive", "Sunset Strip", "Main Street",
    	"La Brea Avenue", "Hollywood Hills", "Pico Boulevard", "Pacific Coast Highway", "Cahuenga Boulevard",
    	"Mulholland Drive", "Figueroa Street", "Jefferson Boulevard", "Lincoln Boulevard", "Flower Street", "Central Avenue"
	],
	"San Francisco": [
    	"Market Street", "Van Ness Avenue", "Mission Street", "Lombard Street", "Geary Street",
    	"California Street", "Fillmore Street", "Union Street", "Haight Street", "Oak Street",
    	"Divisadero Street", "Stockton Street", "Broadway Street", "Bay Street", "Clement Street",
    	"Chestnut Street", "Valencia Street", "22nd Street", "Pier 39", "Folsom Street", "Brannan Street"
	],
	"Houston": [
    	"Main Street", "Westheimer Road", "Richmond Avenue", "Kirby Drive", "Gessner Road",
    	"Southwest Freeway", "Bay Area Boulevard", "Woodway Drive", "Bellaire Boulevard", "Buffalo Speedway",
    	"Shepherd Drive", "Montrose Boulevard", "Bissonnet Street", "Almeda Road", "Memorial Drive",
    	"West Loop North", "North Shepherd Drive", "Washington Avenue", "I-45", "Clearlake City", "Tanglewood"
	],
	"Chicago": [
    	"Michigan Avenue", "State Street", "South Wacker Drive", "Rush Street", "Lake Shore Drive",
    	"Halsted Street", "Clark Street", "Randolph Street", "Roosevelt Road", "Cermak Road",
    	"Broadway Street", "North Avenue", "Lake Street", "Milwaukee Avenue", "Wells Street",
    	"Division Street", "Fullerton Avenue", "Randolph Street", "Madison Street", "Grand Avenue", "Clybourn Avenue"
	],
	"Boston": [
    	"Boylston Street", "Newbury Street", "Beacon Street", "Commonwealth Avenue", "Tremont Street",
    	"Washington Street", "Morton Street", "Charles Street", "Congress Street", "Hanover Street",
    	"Beacon Street", "Summer Street", "Atlantic Avenue", "Day Boulevard", "Franklin Street",
    	"Brookline Avenue", "Tremont Row", "Jersey Street", "Soldiers Field Road", "North Street", "State Street"
	],
	"New York": [
    	"Broadway", "5th Avenue", "Park Avenue", "Madison Avenue", "Wall Street",
    	"Lexington Avenue", "Times Square", "Washington Street", "East River Drive", "Greenwich Street",
    	"7th Avenue", "6th Avenue", "Chambers Street", "Canal Street", "Houston Street",
    	"Bowery Street", "St. Mark's Place", "Delancey Street", "Park Row", "Soho Avenue"
	],
	"Seattle": [
    	"Broadway Avenue", "1st Avenue", "Pike Street", "University Way", "Alaskan Way",
    	"Aurora Avenue", "Capitol Hill", "Lake Union Loop", "Stone Way", "12th Avenue",
    	"Rainier Avenue", "South Lake Union", "East Marginal Way", "Denny Way", "Olive Way",
    	"Northgate Way", "King Street", "Madison Street", "Cherry Street", "Ballard Avenue"
	],
	"Miami": [
    	"Ocean Drive", "Collins Avenue", "Lincoln Road", "Flagler Street", "Biscayne Boulevard",
    	"South Beach Street", "Carter Road", "Altantic Road", "Bay Road", "Brickell Avenue",
    	"Washington Avenue", "Miami Beach Drive", "Hardie Avenue", "Ohio Street", "Venetian Way",
    	"NW 36th Street", "Sunset Drive", "Coral Way", "SW 8th Street", "Le Jeune Road"
	],
	"Dallas": [
    	"Main Street", "Elm Street", "Ross Avenue", "Harwood Street", "Knox Street",
    	"Lemmon Avenue", "Oak Lawn Avenue", "Greenville Avenue", "Mockingbird Lane", "Highland Park Road",
    	"Commerce Street", "Pacific Avenue", "Central Expressway", "Bryan Street", "Columbia Avenue",
    	"Live Oak Street", "Gaston Avenue", "Fairmount Street", "Royal Lane", "Eldorado Parkway"
	],
	"Atlanta": [
    	"Peachtree Street", "Ponce de Leon Avenue", "North Avenue", "Georgia Tech Drive", "West Peachtree Street",
    	"Cobb Parkway", "Spring Street", "Howell Mill Road", "Baker Street", "Decatur Street",
    	"I-285", "Piedmont Road", "Cheshire Bridge Road", "Candler Road", "DeKalb Avenue",
    	"McDonough Boulevard", "Northside Drive", "Edgewood Avenue", "Julian Street", "Old National Highway"
	]
}



df = pd.read_csv('/content/sample_data/r.csv')

# Define a function to get a random street for a given city
def get_random_street(city):
    streets = city_streets.get(city)
    if streets:
        return random.choice(streets)
    return None  # In case the city is not found in the dictionary

# Create a dictionary to store Residence for each Customer_Name
customer_residence = {}

# Define a function to assign a Residence based on Customer_Name and City
def assign_residence(row):
    customer_name = row['Customer_Name']

    # If this Customer_Name hasn't been assigned a residence yet, assign one
    if customer_name not in customer_residence:
        city = row['City']
        residence = get_random_street(city)
        customer_residence[customer_name] = residence

    return customer_residence[customer_name]

# Apply the function to create the new 'Residence' column
df['Residence'] = df.apply(assign_residence, axis=1)

# Save the updated DataFrame to a new CSV file
df.to_csv('updated_r.csv', index=False)

print("Residence column added and saved to updated_r.csv.")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import geopy.distance
import random

# Load the updated_r.csv file
df = pd.read_csv('updated_r.csv')

# Step 1: Data Preprocessing (same as before)

# Handle missing values
df = df.dropna()

# Convert the 'Date' column to datetime type
df['Date'] = pd.to_datetime(df['Date'])

# Extract date-related features
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day_of_week'] = df['Date'].dt.dayofweek

# Encode categorical variables using Label Encoding
label_encoder = LabelEncoder()

# Encode categorical features
df['Customer_Name_Encoded'] = label_encoder.fit_transform(df['Customer_Name'])
df['City_Encoded'] = label_encoder.fit_transform(df['City'])
df['Store_Type_Encoded'] = label_encoder.fit_transform(df['Store_Type'])
df['Season_Encoded'] = label_encoder.fit_transform(df['Season'])
df['Promotion_Encoded'] = label_encoder.fit_transform(df['Promotion'].fillna('No_Promotion'))  # Filling NaNs

# Step 2: Feature Engineering
X = df[['Customer_Name_Encoded', 'City_Encoded', 'Store_Type_Encoded', 'Season_Encoded', 'Promotion_Encoded',
        'Total_Items', 'Year', 'Month', 'Day_of_week']]

y = df['Total_Cost']

# Step 3: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Model Building
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 5: Model Evaluation
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f"RMSE on test data: {rmse}")

# Step 6: Feature Importance
feature_importances = model.feature_importances_
features = X.columns

# Plot feature importance
import matplotlib.pyplot as plt
import seaborn as sns
sns.barplot(x=feature_importances, y=features)
plt.title('Feature Importance')
plt.show()

# Function to simulate the prediction for a new location
def predict_new_store_sales(city, store_type, season, promotion, total_items, year, month, day_of_week):
    new_store_data = pd.DataFrame({
        'Customer_Name_Encoded': [0],  # Placeholder
        'City_Encoded': label_encoder.fit_transform([city])[0],
        'Store_Type_Encoded': label_encoder.fit_transform([store_type])[0],
        'Season_Encoded': label_encoder.fit_transform([season])[0],
        'Promotion_Encoded': label_encoder.fit_transform([promotion])[0],
        'Total_Items': [total_items],
        'Year': [year],
        'Month': [month],
        'Day_of_week': [day_of_week]
    })
    predicted_sales = model.predict(new_store_data)
    return predicted_sales[0]
from geopy.geocoders import Nominatim
import time

# Initialize geocoder
geolocator = Nominatim(user_agent="geo_locator")

# Function to get latitude and longitude
def get_lat_long(city, street):
    try:
        location = geolocator.geocode(f"{street}, {city}")
        if location:
            return location.latitude, location.longitude
        else:
            return None, None
    except Exception as e:
        print(f"Error fetching data for {city}, {street}: {e}")
        return None, None

# Add latitude and longitude columns to the DataFrame
df['Latitude'] = None
df['Longitude'] = None

# Fetch latitude and longitude for each row
for index, row in df.iterrows():
    city = row['City']
    street = row['Street']
    lat, long = get_lat_long(city, street)
    df.at[index, 'Latitude'] = lat
    df.at[index, 'Longitude'] = long


# Save the updated DataFrame to a new CSV file
df.to_csv('updated_r_with_lat_long.csv', index=False)
# Load the updated dataset with latitude and longitude
df = pd.read_csv('updated_r_with_lat_long.csv')

# Simulated function to get all existing store locations
def get_existing_store_locations(df):
    # Only select rows with valid locations (non-null city and street)
    return df[['City', 'Street', 'Store_Type', 'Latitude', 'Longitude']].dropna()

# Proximity Check (to ensure no other similar store is too close to the new one)
def is_proximity_safe(new_lat, new_long, existing_locations, store_type, max_distance_km=1):
    for _, row in existing_locations.iterrows():
        if row['Store_Type'] == store_type:
            existing_lat = row['Latitude']
            existing_long = row['Longitude']
            dist = geopy.distance.distance((new_lat, new_long), (existing_lat, existing_long)).km
            if dist <= max_distance_km:
                return False  # A similar store is too close
    return True

# Now, we want to predict the best street based on our model
def find_best_location_for_new_store():
    # Example of candidate new store
    city = "Los Angeles"
    store_type = "Warehouse Club"
    season = "Fall"
    promotion = "Discount on Selected Items"
    total_items = 10
    year = 2025
    month = 10
    day_of_week = 5  # Friday

    predicted_sales = predict_new_store_sales(city, store_type, season, promotion, total_items, year, month, day_of_week)
    print(f"Predicted sales for new store: ${predicted_sales:.2f}")

    # Get all existing store locations to check proximity
    existing_locations = get_existing_store_locations(df)

    # Simulate the geographic coordinates for a new store (replace with real lat/long)
    new_lat = 34.0522  # Example latitude for Los Angeles
    new_long = -118.2437  # Example longitude for Los Angeles

    # Check if the new store's location is too close to existing stores of the same type
    if is_proximity_safe(new_lat, new_long, existing_locations, store_type):
        # Assign a random street that isn't already occupied
        streets_in_city = df[df['City'] == city]['Street'].unique()
        available_streets = [street for street in streets_in_city if street not in existing_locations['Street'].values]

        if available_streets:
            new_street = random.choice(available_streets)  # Randomly pick an available street
            print(f"Suggested street for the new store: {new_street}")
        else:
            print("No available streets in this city for the new store.")
    else:
        print("Selected location is too close to an existing store. Please select a different location.")

find_best_location_for_new_store()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import geopy.distance
import random
from geopy.geocoders import Nominatim
import time
import matplotlib.pyplot as plt
import seaborn as sns

# Load the updated_r.csv file
df = pd.read_csv('updated_r.csv')

# Step 1: Data Preprocessing (same as before)
df = df.dropna()  # Handle missing values
df['Date'] = pd.to_datetime(df['Date'])  # Convert the 'Date' column to datetime type
df['Year'] = df['Date'].dt.year  # Extract date-related features
df['Month'] = df['Date'].dt.month
df['Day_of_week'] = df['Date'].dt.dayofweek

# Encode categorical variables using Label Encoding
label_encoder = LabelEncoder()

df['Customer_Name_Encoded'] = label_encoder.fit_transform(df['Customer_Name'])
df['City_Encoded'] = label_encoder.fit_transform(df['City'])
df['Store_Type_Encoded'] = label_encoder.fit_transform(df['Store_Type'])
df['Season_Encoded'] = label_encoder.fit_transform(df['Season'])
df['Promotion_Encoded'] = label_encoder.fit_transform(df['Promotion'].fillna('No_Promotion'))  # Filling NaNs

# Step 2: Feature Engineering
X = df[['Customer_Name_Encoded', 'City_Encoded', 'Store_Type_Encoded', 'Season_Encoded', 'Promotion_Encoded',
        'Total_Items', 'Year', 'Month', 'Day_of_week']]
y = df['Total_Cost']

# Step 3: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Model Building
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 5: Model Evaluation
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f"RMSE on test data: {rmse}")

# Step 6: Feature Importance
feature_importances = model.feature_importances_
features = X.columns
sns.barplot(x=feature_importances, y=features)
plt.title('Feature Importance')
plt.show()

# # Function to simulate the prediction for a new location
# def predict_new_store_sales(city, store_type, season, promotion, total_items, year, month, day_of_week):
#     new_store_data = pd.DataFrame({
#         'Customer_Name_Encoded': [0],  # Placeholder
#         'City_Encoded': label_encoder.fit_transform([city])[0],
#         'Store_Type_Encoded': label_encoder.fit_transform([store_type])[0],
#         'Season_Encoded': label_encoder.fit_transform([season])[0],
#         'Promotion_Encoded': label_encoder.fit_transform([promotion])[0],
#         'Total_Items': [total_items],
#         'Year': [year],
#         'Month': [month],
#         'Day_of_week': [day_of_week]
#     })
#     predicted_sales = model.predict(new_store_data)
#     return predicted_sales[0]

# # Increase timeout value and implement rate limiting
# geolocator = Nominatim(user_agent="supermarket_recommender", timeout=10)  # Increase timeout to 10 seconds

# def get_lat_long(city, street):
#     try:
#         location = geolocator.geocode(f"{street}, {city}")
#         if location:
#             return location.latitude, location.longitude
#         else:
#             return None, None
#     except Exception as e:
#         print(f"Error fetching data for {city}, {street}: {e}")
#         return None, None

# # Add Latitude and Longitude to the DataFrame
# def add_lat_long_to_df(df):
#     latitudes = []
#     longitudes = []

#     for _, row in df.iterrows():
#         # Try getting lat/long with rate limiting
#         lat, long = get_lat_long(row['City'], row['Street'])
#         latitudes.append(lat)
#         longitudes.append(long)
#         time.sleep(1)  # Sleep to avoid hitting rate limits (1 second per request)

#     # Add latitudes and longitudes to the dataframe
#     df['Latitude'] = latitudes
#     df['Longitude'] = longitudes
#     return df

# # Assuming you already have 'df' loaded from CSV
# df = add_lat_long_to_df(df)

# # Check the updated dataframe with lat/long
# print(df[['City', 'Street', 'Latitude', 'Longitude']].head())

# # Function to check if new store location is too close to existing stores
# def is_proximity_safe(new_lat, new_long, existing_locations, store_type, max_distance_km=1):
#     for _, row in existing_locations.iterrows():
#         if row['Store_Type'] == store_type:
#             existing_lat = row['Latitude']
#             existing_long = row['Longitude']
#             dist = geopy.distance.distance((new_lat, new_long), (existing_lat, existing_long)).km
#             if dist <= max_distance_km:
#                 return False  # A similar store is too close
#     return True

# # Get all existing store locations (only the ones with lat/long)
# existing_locations = df[['City', 'Street', 'Store_Type', 'Latitude', 'Longitude']].dropna()

# # Example of new store location (simulate lat/long for new store)
# new_lat = 34.0522  # Los Angeles latitude
# new_long = -118.2437  # Los Angeles longitude
# store_type = "Warehouse Club"  # Example store type

# # Check if the new store location is too close to an existing store
# if is_proximity_safe(new_lat, new_long, existing_locations, store_type):
#     print("The location is safe for a new store!")
# else:
#     print("The location is too close to an existing store.")

# # Function to find best location for new store
# def find_best_location_for_new_store():
#     city = "Los Angeles"
#     store_type = "Warehouse Club"
#     season = "Fall"
#     promotion = "Discount on Selected Items"
#     total_items = 10
#     year = 2025
#     month = 10
#     day_of_week = 5  # Friday

#     predicted_sales = predict_new_store_sales(city, store_type, season, promotion, total_items, year, month, day_of_week)
#     print(f"Predicted sales for new store: ${predicted_sales:.2f}")

#     # Get all existing store locations to check proximity
#     existing_locations = df[['City', 'Street', 'Store_Type', 'Latitude', 'Longitude']].dropna()

#     # Simulate the geographic coordinates for a new store (replace with real lat/long)
#     new_lat = 34.0522  # Example latitude for Los Angeles
#     new_long = -118.2437  # Example longitude for Los Angeles

#     # Check if the new store's location is too close to existing stores of the same type
#     if is_proximity_safe(new_lat, new_long, existing_locations, store_type):
#         # Assign a random street that isn't already occupied
#         streets_in_city = df[df['City'] == city]['Street'].unique()
#         available_streets = [street for street in streets_in_city if street not in existing_locations['Street'].values]

#         if available_streets:
#             new_street = random.choice(available_streets)  # Randomly pick an available street
#             print(f"Suggested street for the new store: {new_street}")
#         else:
#             print("No available streets in this city for the new store.")
#     else:
#         print("Selected location is too close to an existing store. Please select a different location.")

# find_best_location_for_new_store()

from geopy.geocoders import Nominatim
import pandas as pd
import time
import joblib

# Initialize Nominatim geocoder with a user-agent
geolocator = Nominatim(user_agent="myGeocoder")

# Load existing cache if available (with joblib)
try:
    lat_long_cache = joblib.load('lat_long_cache.pkl')
    print("Cache loaded successfully.")
except FileNotFoundError:
    lat_long_cache = {}
    print("No existing cache found. Starting fresh.")

# Function to get latitude and longitude with caching
def get_lat_long(city, street):
    address = f"{street.strip()}, {city.strip()}".lower()  # Ensure consistent formatting

    # Check if the result is already in the cache
    if address in lat_long_cache:
        print(f"Cache hit for {address}")
        return lat_long_cache[address]  # Return the cached result

    try:
        # Geocode the address if not found in cache
        location = geolocator.geocode(address)
        if location:
            # Store the fetched latitude and longitude in the cache
            lat_long_cache[address] = (location.latitude, location.longitude)
            return location.latitude, location.longitude
        else:
            return None, None
    except Exception as e:
        print(f"Error fetching data for {city}, {street}: {e}")
        return None, None

# Function to save the cache to a file (after updates)
def save_cache():
    joblib.dump(lat_long_cache, 'lat_long_cache.pkl')
    print("Cache saved.")

# Function to process the DataFrame and get the latitude and longitude for each address
def add_lat_long_to_df(df):
    unique_addresses = set()  # Set to store unique street, city pairs
    lat_long_dict = {}  # Dictionary to store address -> [lat, long]

    # Step 1: Extract unique street, city pairs
    for _, row in df.iterrows():
        address = f"{row['Street'].strip()}, {row['City'].strip()}".lower()
        unique_addresses.add(address)

    # Step 2: Get latitude and longitude for each unique address
    for address in unique_addresses:
        city, street = address.split(", ")
        lat, long = get_lat_long(city, street)
        lat_long_dict[address] = [lat, long]

        # Ensure we don't exceed API limits (1 request per second)
        time.sleep(1)

    # Step 3: Add lat/long to the DataFrame using the dictionary
    latitudes = []
    longitudes = []

    for _, row in df.iterrows():
        address = f"{row['Street'].strip()}, {row['City'].strip()}".lower()
        lat, long = lat_long_dict.get(address, (None, None))  # Default to None if not found
        latitudes.append(lat)
        longitudes.append(long)

    df['Latitude'] = latitudes
    df['Longitude'] = longitudes

    return df, lat_long_dict


# Add lat/long to DataFrame
df, lat_long_dict = add_lat_long_to_df(df)

# Save the updated DataFrame with latitude and longitude to CSV
df.to_csv('updated_store_locations.csv', index=False)

# Save the cache for future use
save_cache()

# Print the resulting DataFrame to verify
print(df[['City', 'Street', 'Latitude', 'Longitude']])

# Optionally print the dictionary for verification
print(lat_long_dict)

# Function to check if new store location is too close to existing stores
def is_proximity_safe(new_lat, new_long, existing_locations, store_type, max_distance_km=1):
    for _, row in existing_locations.iterrows():
        if row['Store_Type'] == store_type:
            existing_lat = row['Latitude']
            existing_long = row['Longitude']
            dist = geopy.distance.distance((new_lat, new_long), (existing_lat, existing_long)).km
            if dist <= max_distance_km:
                return False  # A similar store is too close
    return True

# Get all existing store locations (only the ones with lat/long)
existing_locations = df[['City', 'Street', 'Store_Type', 'Latitude', 'Longitude']].dropna()

# Example of new store location (simulate lat/long for new store)
new_lat = 34.0522  # Los Angeles latitude
new_long = -118.2437  # Los Angeles longitude
store_type = "Warehouse Club"  # Example store type

# Check if the new store location is too close to an existing store
if is_proximity_safe(new_lat, new_long, existing_locations, store_type):
    print("The location is safe for a new store!")
else:
    print("The location is too close to an existing store.")

# Function to find best location for new store
def find_best_location_for_new_store():
    city = "Los Angeles"
    store_type = "Warehouse Club"
    season = "Fall"
    promotion = "Discount on Selected Items"
    total_items = 10
    year = 2025
    month = 10
    day_of_week = 5  # Friday

    predicted_sales = predict_new_store_sales(city, store_type, season, promotion, total_items, year, month, day_of_week)
    print(f"Predicted sales for new store: ${predicted_sales:.2f}")

    # Get all existing store locations to check proximity
    existing_locations = df[['City', 'Street', 'Store_Type', 'Latitude', 'Longitude']].dropna()

    # Simulate the geographic coordinates for a new store (replace with real lat/long)
    new_lat = 34.0522  # Example latitude for Los Angeles
    new_long = -118.2437  # Example longitude for Los Angeles

    # Check if the new store's location is too close to existing stores of the same type
    if is_proximity_safe(new_lat, new_long, existing_locations, store_type):
        # Assign a random street that isn't already occupied
        streets_in_city = df[df['City'] == city]['Street'].unique()
        available_streets = [street for street in streets_in_city if street not in existing_locations['Street'].values]

        if available_streets:
            new_street = random.choice(available_streets)  # Randomly pick an available street
            print(f"Suggested street for the new store: {new_street}")
        else:
            print("No available streets in this city for the new store.")
    else:
        print("Selected location is too close to an existing store. Please select a different location.")

find_best_location_for_new_store()

import joblib
joblib.dump(model, 'location_optimization.pkl')